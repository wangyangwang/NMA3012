---
layout: default
#title:  "Welcome to Jekyll!"
#date:   2015-03-17 21:23:43
#categories: jekyll update
---

<div>
    <h2>Image Processing - Pixel Blending</h2>
</div>

<div>
    <h2>Setting Pixels according to their 2D locations</h2>
    <p>Let's consider this example below</p>
        <div class="row">    
            <div class="col-lg-8">
                <img src="{{ '/img/week7/circles.jpg' | prepend: site.baseurl }}" class="img-responsive">
            </div>
        </div>
    <p>First we ask: which row is our target pixel on ==>row 2</p>
    <p>Then we ask: which column is our target pixel on ==>column 3</p>
    <p>Since there has been 2-1 entire rows of pixels with 3-1 individual pixels ahead of this one, its location in our pixel array should be:
        <br><br>loc = 1*4+2 = 6 or loc = y*width+x </p>
    
    
    {% highlight js %} 
    size(400, 200);
loadPixels();

  //first ask: which row is our pixel on
  for (int y = 0; y < height; y++ ) {
    //then ask: which column is our pixel on
    for (int x = 0; x < width; x++ ) {
     //there has been y entire rows of pixels with x individual pixels ahead of this one, so its location in our pixel array should be
    int loc = y*width+x; 
      if (x % 2 == 0) { // If we are an even column
      pixels[loc] = color(255);
    } else { // If we are an odd column
      pixels[loc] = color(0); //   We use the column number (x) to determine whether the color should be black or white.
    }
  }
}

updatePixels();
{% endhighlight %}    
    
</div>

<div>
    <h2>Additional Pixel Manipulation</h2>
    <h4>Load Image Pixel</h4>
    <h4>Brightness threashhold</h4>
    <h4>Manipulate Pixel with live Kinect input</h4>
    ////////////////////////////////////////////////////////////////////////////////////
/////////////////////////simpleOpenNI integration - don't touch/////////////////////
////////////////////////////////////////////////////////////////////////////////////
 {% highlight js %} 
import SimpleOpenNI.*;
SimpleOpenNI context;
float        zoomF =0.5f;
float        rotX = radians(180);  // by default rotate the hole scene 180deg around the x-axis, 
// the data from openni comes upside down
float        rotY = radians(0);
boolean      autoCalib=true;

PVector      bodyCenter = new PVector();
PVector      bodyDir = new PVector();
PVector      com = new PVector();                                   
PVector      com2d = new PVector();                                   
color[]       userClr = new color[] { 
  color(255, 0, 0), 
  color(0, 255, 0), 
  color(0, 0, 255), 
  color(255, 255, 0), 
  color(255, 0, 255), 
  color(0, 255, 255)
};

PVector jointL = new PVector();  //left hand position
PVector jointH = new PVector(0,0,3000);  //hand position
PVector jointR = new PVector();  //right hand position
////////////////////////////////////////////////////////////////////////////////////
/////////////////////////simpleOpenNI integration - don't touch/////////////////////
////////////////////////////////////////////////////////////////////////////////////


// Two source images
PImage tunnel;      // Source image 1
PImage person;      // Source image 2

// A percentage (10% one image, 90% the other, etc.  starts at 0%);
float p = 0;

void setup() {
////////////////////////////////////////////////////////////////////////////////////
/////////////////////////simpleOpenNI integration - don't touch/////////////////////
////////////////////////////////////////////////////////////////////////////////////
  context = new SimpleOpenNI(this);
  if (context.isInit() == false)
  {
    println("Can't init SimpleOpenNI, maybe the camera is not connected!"); 
    exit();
    return;
  }

  // disable mirror
  context.setMirror(false);

  // enable depthMap generation 
  context.enableDepth();

  // enable skeleton generation for all joints
  context.enableUser();
////////////////////////////////////////////////////////////////////////////////////
/////////////////////////simpleOpenNI integration - don't touch/////////////////////
////////////////////////////////////////////////////////////////////////////////////           
  size(576, 384);
  tunnel = loadImage("tunnel_cropped.jpg");
  person = loadImage("person_cropped.jpg");
}

void draw() {
////////////////////////////////////////////////////////////////////////////////////
/////////////////////////simpleOpenNI integration - don't touch/////////////////////
////////////////////////////////////////////////////////////////////////////////////
  context.update();
////////////////////////////////////////////////////////////////////////////////////
/////////////////////////simpleOpenNI integration - don't touch/////////////////////
////////////////////////////////////////////////////////////////////////////////////

  // Percentage goes from 0 to 1 then back to 0
  if(jointH.z<1500){
    if(p<1){
      p+=0.01;
    }
  }else{
    if(p>0){
      p-=0.01;
    }
  }

  loadPixels();
  // We are going to look at both image's pixels
  tunnel.loadPixels();
  person.loadPixels();

  for (int x = 0; x < tunnel.width; x++ ) {
    for (int y = 0; y < tunnel.height; y++ ) {
      int loc = x*tunnel.height + y;
      // Two colors
      color c0 = tunnel.pixels[loc];
      color c1 = person.pixels[loc];

      // Separate out r,g,b components
      float r0 = red(c0); 
      float g0 = green(c0); 
      float b0 = blue(c0);
      float r1 = red(c1); 
      float g1 = green(c1); 
      float b1 = blue(c1);

      // Combine each image's color
      float r = p*r1+(1.0-p)*r0;
      float g = p*g1+(1.0-p)*g0;
      float b = p*b1+(1.0-p)*b0;

      // Set the new color
      pixels[loc] = color(r, g, b);
    }
  }

  updatePixels();
  // draw the skeleton if it's available
  int[] userList = context.getUsers();
  for (int i=0; i<userList.length; i++)
  {
    if (context.isTrackingSkeleton(userList[i]))
      getBodyDirection(userList[i]);
  }    
}




////////////////////////////////////////////////////////////////////////////////////
/////////////////////////simpleOpenNI integration - don't touch/////////////////////
////////////////////////////////////////////////////////////////////////////////////
void getBodyDirection(int userId)
{  
  float  confidence;

  // draw the joint position
  confidence = context.getJointPositionSkeleton(userId, SimpleOpenNI.SKEL_LEFT_SHOULDER, jointL);
  confidence = context.getJointPositionSkeleton(userId, SimpleOpenNI.SKEL_HEAD, jointH);
  confidence = context.getJointPositionSkeleton(userId, SimpleOpenNI.SKEL_RIGHT_SHOULDER, jointR);
  println(jointH);
  
  //  // take the neck as the center point
  //  confidence = context.getJointPositionSkeleton(userId, SimpleOpenNI.SKEL_NECK, centerPoint);
  //
  //  /*  // manually calc the centerPoint
  //   PVector shoulderDist = PVector.sub(jointL,jointR);
  //   centerPoint.set(PVector.mult(shoulderDist,.5));
  //   centerPoint.add(jointR);
  //   */
  //
  //  PVector up = PVector.sub(jointH, centerPoint);

  //  PVector left = PVector.sub(jointR, centerPoint);
  //
  //  dir.set(up.cross(left));
  //  dir.normalize();
}


void onNewUser(SimpleOpenNI curContext,int userId)
{
  println("onNewUser - userId: " + userId);
  println("\tstart tracking skeleton");
  
  context.startTrackingSkeleton(userId);
}

void onLostUser(SimpleOpenNI curContext,int userId)
{
  println("onLostUser - userId: " + userId);
}

void onVisibleUser(SimpleOpenNI curContext,int userId)
{
  //println("onVisibleUser - userId: " + userId);
}
////////////////////////////////////////////////////////////////////////////////////
/////////////////////////simpleOpenNI integration - don't touch/////////////////////
////////////////////////////////////////////////////////////////////////////////////
 {% endhighlight %}      
</div>
---
layout: default
#title:  "Welcome to Jekyll!"
#date:   2015-03-17 21:23:43
#categories: jekyll update
---
<div>
    <h2>Virtual Reality</h2>
</div>

<div>
    <h2>Virtual Reality as a visual concept</h2>
    <blockquote>"The most elemental process of modern times is the conquest of the world as images."
    <footer>Martin Heidegger, Holzwege, p. 92. Frankfurt: Klostermann (1980).</footer>
    </blockquote>
    <p>In virtual space, both historically and in the present, the illusion works on two levels: first, there is the classic function of illusion which is the playful and conscious submission to appearance that is the aesthetic enjoyment of illusion. Second, by intensifying the suggestive image effects and through appearance, this can temporarily overwhelm perception of the difference between mage space and reality. This suggestive power may, for a certain time, suspend the relationship between subject and object, and the "as if" may have effects on awareness. The power of a hitherto unknown or perfected medium of illusion to deceive the senses leads the observer to act or feel according to the scene or logic of the images and, to a certain degree, may even succeed in captivating awareness. This is the starting point for historic illusion spaces and their immersive successors in art and media history. They use mutlimedia to increase and maximize suggestion in order to erode the inner distance of the observer and ensure maximum effect for their message.</p>
</div>

<div>
    <h2>Virtual Reality as an artistic concept</h2>
    <h4>Lee Ufan - Making Infinity</h4>
    <p>Lee was born in southern Korea in 1936 and witnessed the political convulsions that beset the Korean peninsula from the Japanese occupation to the Korean War, which left the country divided in 1953. He studied painting at the College of Fine Arts at Seoul National University and soon moved to Japan, where he earned a degree in philosophy. Over the last 40 years, he has lived and worked in Korea, Japan, and France, becoming a transnational artist in a postmodern world before those terms were current. "The dynamics of distance have made me what I am," he remarks.
    <br><br>In the late 1960s, in an artistic environment emphasizing ideas of system, structure, and process, Lee emerged as the theoretical leader of Mono-ha (literally, "School of Things"), a Japanese movement that arose amid the collapse of colonial world orders, antiauthoritarian protests, and the rise of critiques of modernity. Lee’s sculptures, presenting dispersed arrangements of stones together with industrial materials like steel plates, rubber sheets, and glass panes, recast the object as a network of relations based on parity among the viewer, materials, and site. Lee was a pivotal figure in the Korean tansaekhwa (monochrome painting) school, which offered a fresh approach to minimalist abstraction by presenting repetitive gestural marks as bodily records of time’s perpetual passage. Deeply versed in modern philosophy and Asian metaphysics, Lee has coupled his artistic practice with a prodigious body of critical and philosophical writings.
    <br><br>Marking Infinity is organized to reflect Lee’s method of working in iterative series and spans the 1960s to the present. Whether brush marks on canvas or stones placed just so on the ground, his markings in space elicit momentary, open-ended situations that engage the viewer viscerally. His distilled gestures, manifesting an extraordinary ethics of restraint, create an emptiness that is paradoxically generative and vivid. Relatum (formerly Phenomena and Perception A, 1969) presents three rocks laid on a latex band marked as a measuring tape. The weight of the rocks causes the band to stretch and buckle, disrupting the system of measurement it codes and reminding us of the capriciousness of rational truth: what you see is a result of where you stand.</p>
    <br><a href="http://www.chateauversailles-spectacles.fr/en/spectacles/2014/lee-ufan-versailles">Lee Ufan and Chateu De Versailles</a>
    <br><a href="http://www.luxuo.com/art/joana-vasconcelos-exhibition-palace-of-versailles.html">Joana Vasconcelos and Palace of Versallies</a>
    <br><a href="http://mashkulture.net/2014/01/03/the-hypnotizingly-minimal-gifs-of-david-dope/#more-98168">David Dope - defining new standards for graphic based asthetics</a>
    <br><a href="https://artcom.de/en/department/art-en/">ART+COM, parametric design and digital fabrication</a>
    <br><a href="The Kármán Line">2015 BAFTA Awards Nominee for Best British Short Film - The Karmar Line by Oscar Sharp</a>
</div>

    <div>
        <h4>Brent Watanabe</h4>
        <a href="https://vimeo.com/62226233">for(){}; - Computer Game mapped on canvas</a>
        <br><a href="http://bwatanabe.com/MacDowell_2013.html">Brent Watanabe</a>
    </div>  

    <div>
        <h4>Skullmapping</h4>
        <a href="http://www.skullmapping.com/">Skullmapping is a French artistic collective run by Antoon Verbeeck and Filip Sterckx</a>
        <br><a href="https://vimeo.com/97645686">The Skyx</a>
    </div>


<div>
    <h2>Image Processing - Pixel Blending</h2>
</div>

<div>
    <h4>Setting Pixels according to their 2D locations</h4>
    <p>Let's consider this example below</p>
        <div class="row">    
            <div class="col-lg-8">
                <img src="{{ '/img/week7/circles.jpg' | prepend: site.baseurl }}" class="img-responsive">
            </div>
        </div>
    <p>First we ask: which row is our target pixel on ==>row 2</p>
    <p>Then we ask: which column is our target pixel on ==>column 3</p>
    <p>Since there has been 2-1 entire rows of pixels with 3-1 individual pixels ahead of this one, its location in our pixel array should be:
        <br><br>loc = 1*4+2 = 6 or loc = y*width+x </p>
    
    
    {% highlight js %} 
    size(400, 200);
loadPixels();

  //first ask: which row is our pixel on
  for (int y = 0; y < height; y++ ) {
    //then ask: which column is our pixel on
    for (int x = 0; x < width; x++ ) {
     //there has been y entire rows of pixels with x individual pixels ahead of this one, so its location in our pixel array should be
    int loc = y*width+x; 
      if (x % 2 == 0) { // If we are an even column
      pixels[loc] = color(255);
    } else { // If we are an odd column
      pixels[loc] = color(0); //   We use the column number (x) to determine whether the color should be black or white.
    }
  }
}

updatePixels();
{% endhighlight %}    
    
</div>

<div>
    <h2>Additional Pixel Manipulation</h2>
    <h4>Load Image Pixel</h4>
    <h4>Brightness threashhold</h4>
    <h4>Pixel Blending</h4>
    <h4>Manipulate Pixel with live Kinect input</h4>
{% highlight js %}    ////////////////////////////////////////////////////////////////////////////////////
/////////////////////////simpleOpenNI integration - don't touch/////////////////////
////////////////////////////////////////////////////////////////////////////////////
import SimpleOpenNI.*;
SimpleOpenNI context;
float        zoomF =0.5f;
float        rotX = radians(180);  // by default rotate the hole scene 180deg around the x-axis, 
// the data from openni comes upside down
float        rotY = radians(0);
boolean      autoCalib=true;

PVector      bodyCenter = new PVector();
PVector      bodyDir = new PVector();
PVector      com = new PVector();                                   
PVector      com2d = new PVector();                                   
color[]       userClr = new color[] { 
  color(255, 0, 0), 
  color(0, 255, 0), 
  color(0, 0, 255), 
  color(255, 255, 0), 
  color(255, 0, 255), 
  color(0, 255, 255)
};

PVector jointL = new PVector();  //left hand position
PVector jointH = new PVector(0,0,3000);  //hand position
PVector jointR = new PVector();  //right hand position
////////////////////////////////////////////////////////////////////////////////////
/////////////////////////simpleOpenNI integration - don't touch/////////////////////
////////////////////////////////////////////////////////////////////////////////////


// Two source images
PImage tunnel;      // Source image 1
PImage person;      // Source image 2

// A percentage (10% one image, 90% the other, etc.  starts at 0%);
float p = 0;

void setup() {
////////////////////////////////////////////////////////////////////////////////////
/////////////////////////simpleOpenNI integration - don't touch/////////////////////
////////////////////////////////////////////////////////////////////////////////////
  context = new SimpleOpenNI(this);
  if (context.isInit() == false)
  {
    println("Can't init SimpleOpenNI, maybe the camera is not connected!"); 
    exit();
    return;
  }

  // disable mirror
  context.setMirror(false);

  // enable depthMap generation 
  context.enableDepth();

  // enable skeleton generation for all joints
  context.enableUser();
////////////////////////////////////////////////////////////////////////////////////
/////////////////////////simpleOpenNI integration - don't touch/////////////////////
////////////////////////////////////////////////////////////////////////////////////           
  size(576, 384);
  tunnel = loadImage("tunnel_cropped.jpg");
  person = loadImage("person_cropped.jpg");
}

void draw() {
////////////////////////////////////////////////////////////////////////////////////
/////////////////////////simpleOpenNI integration - don't touch/////////////////////
////////////////////////////////////////////////////////////////////////////////////
  context.update();
////////////////////////////////////////////////////////////////////////////////////
/////////////////////////simpleOpenNI integration - don't touch/////////////////////
////////////////////////////////////////////////////////////////////////////////////

  // Percentage goes from 0 to 1 then back to 0
  if(jointH.z<1500){
    if(p<1){
      p+=0.01;
    }
  }else{
    if(p>0){
      p-=0.01;
    }
  }

  loadPixels();
  // We are going to look at both image's pixels
  tunnel.loadPixels();
  person.loadPixels();

  for (int x = 0; x < tunnel.width; x++ ) {
    for (int y = 0; y < tunnel.height; y++ ) {
      int loc = x*tunnel.height + y;
      // Two colors
      color c0 = tunnel.pixels[loc];
      color c1 = person.pixels[loc];

      // Separate out r,g,b components
      float r0 = red(c0); 
      float g0 = green(c0); 
      float b0 = blue(c0);
      float r1 = red(c1); 
      float g1 = green(c1); 
      float b1 = blue(c1);

      // Combine each image's color
      float r = p*r1+(1.0-p)*r0;
      float g = p*g1+(1.0-p)*g0;
      float b = p*b1+(1.0-p)*b0;

      // Set the new color
      pixels[loc] = color(r, g, b);
    }
  }

  updatePixels();
  // draw the skeleton if it's available
  int[] userList = context.getUsers();
  for (int i=0; i<userList.length; i++)
  {
    if (context.isTrackingSkeleton(userList[i]))
      getBodyDirection(userList[i]);
  }    
}




////////////////////////////////////////////////////////////////////////////////////
/////////////////////////simpleOpenNI integration - don't touch/////////////////////
////////////////////////////////////////////////////////////////////////////////////
void getBodyDirection(int userId)
{  
  float  confidence;

  // draw the joint position
  confidence = context.getJointPositionSkeleton(userId, SimpleOpenNI.SKEL_LEFT_SHOULDER, jointL);
  confidence = context.getJointPositionSkeleton(userId, SimpleOpenNI.SKEL_HEAD, jointH);
  confidence = context.getJointPositionSkeleton(userId, SimpleOpenNI.SKEL_RIGHT_SHOULDER, jointR);
  println(jointH);
  
  //  // take the neck as the center point
  //  confidence = context.getJointPositionSkeleton(userId, SimpleOpenNI.SKEL_NECK, centerPoint);
  //
  //  /*  // manually calc the centerPoint
  //   PVector shoulderDist = PVector.sub(jointL,jointR);
  //   centerPoint.set(PVector.mult(shoulderDist,.5));
  //   centerPoint.add(jointR);
  //   */
  //
  //  PVector up = PVector.sub(jointH, centerPoint);

  //  PVector left = PVector.sub(jointR, centerPoint);
  //
  //  dir.set(up.cross(left));
  //  dir.normalize();
}


void onNewUser(SimpleOpenNI curContext,int userId)
{
  println("onNewUser - userId: " + userId);
  println("\tstart tracking skeleton");
  
  context.startTrackingSkeleton(userId);
}

void onLostUser(SimpleOpenNI curContext,int userId)
{
  println("onLostUser - userId: " + userId);
}

void onVisibleUser(SimpleOpenNI curContext,int userId)
{
  //println("onVisibleUser - userId: " + userId);
}
////////////////////////////////////////////////////////////////////////////////////
/////////////////////////simpleOpenNI integration - don't touch/////////////////////
////////////////////////////////////////////////////////////////////////////////////
 {% endhighlight %}      
</div>
    
<div>
    <h2>Video Manipulation</h2>
    <h4>Capture Live Video</h4>
    {% highlight js %} 
    import processing.video.*;

Capture video; //declare a capture object called video

void setup() {
  size(640, 480);
  println(Capture.list());

  // initialize video object, use the default camera at 320x240 resolution
  video = new Capture(this, 640, 480);
  video.start();
}

// An event for when a new frame is available, similar to mousePressed
void captureEvent(Capture video) {
  // Step 4. Read the image from the camera.
  video.read();
}

void draw() {
  // Step 5. Display the video image.
  image(video, 0, 0);
}
    {% endhighlight %} 
    
    <h4>Movie Scrub</h4>
    
    <h4>Play Speed</h4>
    <h4>Live Pixel Blending</h4>
</div>

<div>
    <h2>Assignment</h2>
    <p>Read chapters on Images and Videos</p>
    <p>Create a sketch using Images or Video manipulation</p>
</div>

